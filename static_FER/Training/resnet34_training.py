# -*- coding: utf-8 -*-
"""ResNet34_training.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/126G-p_TuQR5LST_6PHNmAn2WMlKnFTaK

"""


from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation, Flatten
from keras.layers import Conv2D, Conv3D, MaxPooling2D, BatchNormalization, AveragePooling2D,GlobalAveragePooling2D
from keras.losses import categorical_crossentropy
from keras.optimizers import Adam, Adamax
from keras.callbacks import ReduceLROnPlateau, TensorBoard, EarlyStopping, ModelCheckpoint
from keras.models import load_model
from keras.regularizers import l2
from keras.layers import Input, Add
from keras.models import Model

num_features = 64
num_labels = 7
batch_size = 64
epochs = 100
input_shape = (48, 48, 3)

def conv_1(input_layer):

    x =Conv2D(64, (5, 5), strides =2, padding="same")(input_layer)
    x =BatchNormalization()(x)
    x = Activation("relu")(x)
    x = MaxPooling2D()(x)

    return x
    

def conv_bat_rel(input_, filters, skip_stride = False):
    """
    convolution, then batch, then relu combo
    However, if this combo is the first combo within a resblock, we need to
    reduce dimensional output via stride 2.
    If skip_stride = True, we set stride = 2

    """

    if skip_stride:
         x =Conv2D(filters, (3, 3), strides =2, padding="same")(input_)
    else:
        x =Conv2D(filters, (3, 3), strides =1, padding="same")(input_)
    x =BatchNormalization()(x)
    x = Activation("relu")(x)
    return x

def conv_bat(input_, filters):
    "just conv followed by batch for when we need to add the residuals"
    x =Conv2D(filters, (3, 3), strides =1, padding="same")(input_)
    x =BatchNormalization()(x)
    return x


def single_cov(input_, filters):
    "1x1 convolution filter when we need to reduce dimensionality of residual"
    x =Conv2D(filters, (1, 1), strides =2, padding="same")(input_)
    
    return x
    

def res_block(input_, filters, skip_stride = False):
    "One complete res block which consists of two conv layers and adds the residual"
    x =conv_bat_rel(input_, filters, skip_stride = skip_stride)
    x =conv_bat(x, filters)
    if skip_stride:
        input_ = single_cov(input_, filters)
    x = Add()([x,input_])
    x = Activation("relu")(x)

    return x



def architecture(res_blocks, filters_list):
    "the complete architecture using all above functions"
    input_layer = Input(shape=(48,48, 3))
    x =conv_1(input_layer)
    for block, filters, reduce_conv in  zip(res_blocks, filters_list, reduction_convs):
        for num,connection in enumerate(range(block)):
            if num == 0 and reduce_conv:
                x =res_block(x, filters, skip_stride = True)
            else:
                x =res_block(x, filters, skip_stride = False)

    x =GlobalAveragePooling2D()(x)
    x = Dense(128, activation='relu')(x)
    x = Dropout(0.5)(x)
    predictions = Dense(classes, activation='softmax')(x)
    print(predictions.shape)
    model = Model(inputs= input_layer, outputs=predictions)
   

    

    return model

res_blocks = [3,4, 6, 3]
filters_list = [64,128,256,512]
reduction_convs = [False, True, True, True] #This points to the blocks that will downsize their first convlayer via stride 2

classes = 7      
model = architecture(res_blocks, filters_list)

model.summary()



lr_reducer = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=10, verbose=1)
tensorboard = TensorBoard(log_dir='./logs')
early_stopper = EarlyStopping(monitor='val_loss', min_delta=0, patience=20, verbose=1, mode='auto')
checkpointer = ModelCheckpoint("/drive", monitor='val_loss', verbose=1, save_best_only=True)

model.compile(loss=categorical_crossentropy,
              optimizer=Adamax(),
              metrics=['accuracy'])

model.load_weights('/gdrive/My Drive/big_data_milestone2/model/face_expr_resnet34_2.h5')

model.fit(X_train,Y_train,
          batch_size=32,
          epochs=500,
          verbose=1,
          validation_data=(X_valid, Y_valid),
          shuffle=True,
          callbacks=[lr_reducer, tensorboard, early_stopper, checkpointer])

model.evaluate(X_test, Y_test)

model.save_weights('/gdrive/My Drive/big_data_milestone2/model/face_expr_resnet34_0.58.h5')

model_n = architecture(res_blocks, filters_list)

from keras.preprocessing.image import ImageDataGenerator
gen = ImageDataGenerator()
train_generator = gen.flow(X_train, Y_train, batch_size=32)
 
model_n.compile(loss='categorical_crossentropy'
, optimizer=Adamax(lr=0.0005)
, metrics=['accuracy']
)

model_n.load_weights('/gdrive/My Drive/big_data_milestone2/model/face_expr_resnet34_0.58.h5')

model_n.fit_generator(train_generator, steps_per_epoch=50, epochs=100)

model_n.evaluate(X_test, Y_test)

model_n.save_weights('/gdrive/My Drive/big_data_milestone2/model/face_expr_resnet34_0.6035.h5')

